# Report Format

Use this template structure when generating the trace audit report. Adapt sections as needed based on findings — omit empty sections, but always include the overview and summary.

---

## Output Template

```markdown
# Trace Performance Audit

## Trace Overview

| Property | Value |
|----------|-------|
| **Site URL** | `{url}` |
| **Trace Duration** | {duration_seconds}s |
| **Processes** | {process_list} |
| **Trace File** | `{filename}` |

---

## Critical Issues

{For each critical-severity finding, create a subsection:}

### {issue_number}. {Category}: {brief description}

- **Severity:** CRITICAL
- **Count:** {count} occurrences
- **Worst offender:** {duration}ms at t={timestamp}s
- **Details:** {specific details — affected URLs, function names, element counts, etc.}
- **Fix:** {actionable recommendation}

---

## Warnings

{For each warning-severity finding, create a subsection:}

### {issue_number}. {Category}: {brief description}

- **Severity:** WARNING
- **Count:** {count} occurrences
- **Worst offender:** {duration}ms at t={timestamp}s
- **Fix:** {actionable recommendation}

---

## Metrics Summary

| Metric | Value | Rating |
|--------|-------|--------|
| **CLS** | {score} | {Good / Needs Improvement / Poor} |
| **INP** | {duration}ms | {Good / Needs Improvement / Poor} |
| **Long Tasks** | {count} | {count} > 50ms, {count} > 200ms |
| **Total Blocking Time** | {sum of long task excess}ms | — |
| **GC Pauses** | {count} ({total_dur}ms total) | — |
| **Layout Shifts** | {count} (CLS: {score}) | — |
| **Forced Reflows** | {count} | — |
| **Network Errors** | {count} | — |
| **Script Eval Time** | {total}ms across {count} scripts | — |

{Omit rows for metrics with zero findings. Add rows for any additional metrics discovered.}

---

## Timeline Hotspots

{Identify 500ms windows where multiple issues overlap. List the top 3-5 hotspots:}

| Time Range | Issues | Severity |
|------------|--------|----------|
| {start}s – {end}s | {comma-separated list of issue categories} | {highest severity in range} |

{For each hotspot, briefly describe what's happening in that time window.}

---

## Recommendations

{Ordered list of actionable fixes, prioritized by impact:}

1. **{Fix title}** — {Description of what to change and why. Reference the specific issue above.}
2. **{Fix title}** — {Description.}
3. ...

---

*Report generated by trace-audit skill*
```

## Severity Badges

When using inline severity indicators:
- **CRITICAL** — use bold or `**CRITICAL**`
- **WARNING** — use bold or `**WARNING**`
- **Good** — no special formatting needed

## Rating Thresholds (Web Vitals)

| Metric | Good | Needs Improvement | Poor |
|--------|------|-------------------|------|
| CLS | <= 0.1 | 0.1 – 0.25 | > 0.25 |
| INP | <= 200ms | 200ms – 500ms | > 500ms |
| LCP | <= 2.5s | 2.5s – 4.0s | > 4.0s |

## Formatting Guidelines

- Use tables for structured data, not bullet lists
- Include timestamps in seconds relative to trace start (not raw µs)
- Round durations to 1 decimal place (e.g., 52.3ms, not 52341µs)
- For URLs, truncate to the last path segment if very long, showing full URL in details
- Group related issues together (e.g., all layout-related issues near each other)
- If there are no critical issues, lead with a positive note before listing warnings
